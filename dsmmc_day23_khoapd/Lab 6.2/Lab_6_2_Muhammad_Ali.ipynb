{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV-HVmVVkopV"
   },
   "source": [
    "# Muhammad Ali\n",
    "\n",
    "Thời lượng ước tính: **120** phút\n",
    "\n",
    "## Giới thiệu Lab\n",
    "Trong quá trình trưởng thành, ai cũng hâm mộ một vị anh hùng. Đối với nhiều người, vị anh hùng đó là Muhammad Ali. Ông ấy dạy mọi người nên tự hào về con người của họ, kể cả vào thời điểm mà những người khác sẽ không chấp nhận điều đó. Ông đã chỉ cho mọi người cách đứng lên bảo vệ niềm tin khi đối mặt với áp bức và bạo quyền. Ông giúp mọi người đánh giá cao bản thân và khuyến khích họ quan tâm đến những người xung quanh. Ông đã cho chúng ta thấy bản lĩnh thực sự có nghĩa là gì, làm thế nào để trở thành một võ sĩ quyền anh, và nhiều hơn thế nữa. Tất cả những người từng gặp Muhammad Ali, dù là trên hay ngoài võ đài đều có một câu chuyện đầy động lực để chia sẻ về cuộc gặp gỡ của họ.\n",
    "\n",
    "Vào ngày 3 tháng 6 năm 2016, Muhammad Ali qua đời ở tuổi 74 do sốc nhiễm trùng. Trước đó 30 năm, ông được chẩn đoán mắc hội chứng Parkinson, một tình trạng thoái hóa thần kinh mà các bác sĩ cho rằng do chấn thương não liên quan đến quyền anh.\n",
    "\n",
    "Bản thân bệnh Parkinson là một rối loạn lâu dài của hệ thần kinh, ảnh hưởng đến nhiều khía cạnh vận động của một người theo thời gian. Người bệnh này có đặc điểm là run, di chuyển chậm, cứng nhắc, sa sút trí tuệ và trầm cảm. Vào năm 2013, khoảng 53 triệu người được chẩn đoán mắc bệnh này, chủ yếu là nam giới. Những nhân vật nổi tiếng khác bị ảnh hưởng bởi nó gồm diễn viên Michael J. Fox, và vận động viên đua xe đạp Olympic Davis Phinney.\n",
    "\n",
    "Trong lab này, bạn sẽ áp dụng SVC cho [Tập dữ liệu Parkinson](https://archive.ics.uci.edu/ml/datasets/Parkinsons), được cung cấp bởi Machine Learning Repository của UCI. Tập dữ liệu được thực hiện ở Đại học Oxford, với sự hợp tác của 10 trung tâm y tế trên khắp Hoa Kỳ cùng với Intel, tổ chức đã phát triển thiết bị được sử dụng để ghi lại các thuộc tính chính của tập dữ liệu: tín hiệu giọng nói. Mục tiêu của bạn đối với lab này trước tiên là xem liệu có thể phân biệt được những người bị và không bị Parkinson sử dụng công cụ phân loại vectơ hỗ trợ của SciKit-Learn hay không, và sau đó là tìm hiểu một cách thuần phác trong việc tinh chỉnh các thông số với nỗ lực tối đa hóa độ chính xác của testing set.\n",
    "\n",
    "\"Tôi chưa bao giờ thực sự chán nản với những việc khó khăn bởi vì tôi luôn thích nó. Thức dậy mỗi sáng để làm việc trên đường. Đến phòng tập thể dục hàng ngày lúc 12 giờ. Tôi không bao giờ thay đổi khuôn khổ của mình.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKeHrzNmkopX"
   },
   "source": [
    "## Chu kỳ 1"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T19:54:24.650957Z",
     "start_time": "2024-07-11T19:54:23.158576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEbWvbYKkopZ"
   },
   "source": [
    "Load **parkinsons.data** vào biến **X**, hãy chắc chắn rằng bạn bỏ cột name.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9G6Oi5d4kopa",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:02:55.056120Z",
     "start_time": "2024-07-11T20:02:54.725083Z"
    }
   },
   "source": [
    "# Nhập code của bạn ở đây\n",
    "data_df = pd.read_csv('parkinsons.data', sep = ',')\n",
    "data_parkinsons = data_df.drop(columns = \"name\")\n",
    "data_parkinsons.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_parkinsons.dtypes",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDVP:Fo(Hz)         float64\n",
       "MDVP:Fhi(Hz)        float64\n",
       "MDVP:Flo(Hz)        float64\n",
       "MDVP:Jitter(%)      float64\n",
       "MDVP:Jitter(Abs)    float64\n",
       "MDVP:RAP            float64\n",
       "MDVP:PPQ            float64\n",
       "Jitter:DDP          float64\n",
       "MDVP:Shimmer        float64\n",
       "MDVP:Shimmer(dB)    float64\n",
       "Shimmer:APQ3        float64\n",
       "Shimmer:APQ5        float64\n",
       "MDVP:APQ            float64\n",
       "Shimmer:DDA         float64\n",
       "NHR                 float64\n",
       "HNR                 float64\n",
       "status                int64\n",
       "RPDE                float64\n",
       "DFA                 float64\n",
       "spread1             float64\n",
       "spread2             float64\n",
       "D2                  float64\n",
       "PPE                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ixw-1DImf_K"
   },
   "source": [
    "Ghép cột status vào biến **y** và xóa nó khỏi **X**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nOWlWytYm0VV",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:03:04.173429Z",
     "start_time": "2024-07-11T20:03:04.147880Z"
    }
   },
   "source": [
    "# Nhập code của bạn ở đây\n",
    "status_df = data_parkinsons['status']\n",
    "data_parkinsons = data_parkinsons.drop(columns = 'status')\n",
    "data_parkinsons.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  MDVP:Jitter(Abs)  \\\n",
       "0      119.992       157.302        74.997         0.00784           0.00007   \n",
       "1      122.400       148.650       113.819         0.00968           0.00008   \n",
       "2      116.682       131.111       111.555         0.01050           0.00009   \n",
       "3      116.676       137.871       111.366         0.00997           0.00009   \n",
       "4      116.014       141.781       110.655         0.01284           0.00011   \n",
       "\n",
       "   MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  MDVP:Shimmer(dB)  ...  \\\n",
       "0   0.00370   0.00554     0.01109       0.04374             0.426  ...   \n",
       "1   0.00465   0.00696     0.01394       0.06134             0.626  ...   \n",
       "2   0.00544   0.00781     0.01633       0.05233             0.482  ...   \n",
       "3   0.00502   0.00698     0.01505       0.05492             0.517  ...   \n",
       "4   0.00655   0.00908     0.01966       0.06425             0.584  ...   \n",
       "\n",
       "   MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1  \\\n",
       "0   0.02971      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031   \n",
       "1   0.04368      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192   \n",
       "2   0.03590      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179   \n",
       "3   0.03772      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501   \n",
       "4   0.04465      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02971</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04368</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03590</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03772</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04465</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag3LaZ_fm2bX"
   },
   "source": [
    "Thực hiện train/test split. **30**% kích thước nhóm test, với random_state bằng **7**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HJVbkRsvnD3K",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:03:07.135876Z",
     "start_time": "2024-07-11T20:03:07.128986Z"
    }
   },
   "source": [
    "# Nhập code của bạn ở đây\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_parkinsons, status_df, test_size = 0.3, random_state = 7)\n",
    "print('Train set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (136, 22) (136,)\n",
      "Test set: (59, 22) (59,)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-gCEYNFnK3Q"
   },
   "source": [
    "Tạo bộ phân loại SVC. Không chỉ định bất kỳ tham số nào, chỉ để mọi thứ như mặc định. So khớp nó với dữ liệu huấn luyện và sau đó chấm điểm dữ liệu test với độ chính xác và F1 score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GPuI1e4enNjd",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:23:06.663777Z",
     "start_time": "2024-07-11T20:23:06.650394Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# Nhập code của bạn ở đây\n",
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "status_pred = svc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, status_pred)\n",
    "f1 = f1_score(y_test, status_pred)\n",
    "\n",
    "print(\"Accuracy score:\", accuracy)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7627118644067796\n",
      "F1 score: 0.86\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H8GDqSFnPu6"
   },
   "source": [
    "## Chu kỳ 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrUv89B0nV9U"
   },
   "source": [
    "Độ chính xác đó quá thấp để trở nên hữu dụng. Chúng ta cần phải cải thiện nó. Bạn có thể thực hiện thử theo cách thủ công một loạt các kết hợp của **C và các giá trị gamma cho nhân rbf**. Nhưng điều đó có thể tốn rất nhiều thời gian. Ngoài ra, bạn có thể vô tình bỏ qua một cặp giá trị có thể dẫn đến độ chính xác rất tốt.\n",
    "\n",
    "Thay vào đó, hãy tận dụng ưu điểm của máy tính. Lập trình tìm kiếm thông số tốt nhất đơn giản bằng cách tạo các vòng lặp for lồng nhau. Vòng lặp for bên ngoài sẽ lặp lại biến **C từ 0,05 đến 2, sử dụng tăng tiến đơn vị 0,05**. Vòng lặp for bên trong sẽ tăng biến **gamma từ 0,001 đến 0,1, sử dụng tăng tiến đơn vị 0,001**. Như bạn đã biết, Python range sẽ không cho phép khoảng thời gian thực, vì thế bạn sẽ phải thực hiện một số nghiên cứu về NumPy ARanges nếu bạn chưa biết cách sử dụng chúng.\n",
    "\n",
    "Vì mục tiêu là tìm các tham số dẫn đến mô hình có hệ số chính xác tốt nhất, bạn sẽ cần biến **best_score = 0 mà bạn khởi tạo bên ngoài vòng lặp for.** Trong vòng lặp for bên trong, hãy tạo mô hình SVC và chuyển tham số C và gamma vào hàm tạo lớp. Huấn luyện và cho điểm mô hình một cách thích hợp. Nếu best_score hiện tại nhỏ hơn hệ số của mô hình, hãy cập nhật best_score để đảm bảo in nó ra cùng với các giá trị C và gamma dẫn đến nó.\n",
    "\n",
    "Sau khi chạy lại lab, độ chính xác cao nhất và hệ số F1 mà bạn có thể nhận được là bao nhiêu?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "efWGEUPNnO0E",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:27:59.709287Z",
     "start_time": "2024-07-11T20:27:55.987094Z"
    }
   },
   "source": [
    "# Nhập code của bạn ở đây\n",
    "min_c = 0.05\n",
    "max_c = 2\n",
    "\n",
    "min_gamma = 0.001\n",
    "max_gamma = 0.1\n",
    "\n",
    "best_score = 0\n",
    "best_gamma = 0\n",
    "best_C = 0\n",
    "\n",
    "for i in np.arange(min_c, max_c, 0.05):\n",
    "\tfor j in np.arange(min_gamma, max_gamma, 0.01):\n",
    "\t\tsvc = svm.SVC(gamma = j, C = i)\n",
    "\t\tsvc.fit(X_train, y_train)\n",
    "\t\tstatus_pred = svc.predict(X_test)\n",
    "\t\taccuracy = accuracy_score(y_test, status_pred)\n",
    "\t\tf1 = f1_score(y_test, status_pred)\n",
    "\n",
    "\t\tprint(\"Accuracy score:\", accuracy)\n",
    "\t\tprint(\"F1 score:\", f1)\n",
    "\t\tif f1 > best_score:\n",
    "\t\t\tbest_score = f1\n",
    "\t\t\tbest_gamma = j\n",
    "\t\t\tbest_C = i\n",
    "\n",
    "print(f\"best score is {best_score}\")\n",
    "print(f\"best gamma is {best_gamma}\")\n",
    "print(f\"best C is {best_C}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9108910891089109\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.9090909090909091\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.847457627118644\n",
      "F1 score: 0.912621359223301\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9183673469387755\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9278350515463918\n",
      "Accuracy score: 0.8813559322033898\n",
      "F1 score: 0.9306930693069307\n",
      "Accuracy score: 0.864406779661017\n",
      "F1 score: 0.9215686274509803\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8305084745762712\n",
      "F1 score: 0.9038461538461539\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.8135593220338984\n",
      "F1 score: 0.8952380952380953\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "Accuracy score: 0.7966101694915254\n",
      "F1 score: 0.8867924528301887\n",
      "best score is 0.9306930693069307\n",
      "best gamma is 0.011\n",
      "best C is 1.1500000000000001\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZev_qCYnylw"
   },
   "source": [
    "## Chu kỳ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqM4tWC4n_Gk"
   },
   "source": [
    "Đợi một chút. Kéo mở tệp nhãn của tập dữ liệu từ: https://archive.ics.uci.edu/ml/datasets/Parkinsons\n",
    "\n",
    "\n",
    "\n",
    "Nhìn vào các đơn vị trên các cột: **Hz,%, Abs, dB, ...** Điều gì đã xảy ra với việc chuyển đổi dữ liệu? Tất cả các đơn vị đó tương tác với nhau, một số quá trình tiền xử lý chắc chắn là theo thứ tự.\n",
    "Ngay sau khi bạn định dạng trước train/test split nhưng trước khi bạn huấn luyện mô hình, hãy nhập code tiền xử lý của SciKit-Learn. Trừ khi bạn biết rõ cái nào sẽ hoạt động tốt nhất, nếu không bạn sẽ phải thử từng bộ tiền xử lý khác nhau, kiểm tra xem chúng có cải thiện độ chính xác dự đoán hay không.\n",
    "\n",
    "Hãy thử với ***Normalizer(), MaxAbsScaler(), MinMaxScaler(), KernelCenterer(), and StandardScaler().***\n",
    "\n",
    "Sau khi thử tất cả các tỷ lệ này, độ chính xác cao nhất mới và hệ số F1 mà bạn có thể đạt được là bao nhiêu?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i828Tr31n-Nu",
    "ExecuteTime": {
     "end_time": "2024-07-11T20:50:51.457316Z",
     "start_time": "2024-07-11T20:50:51.411531Z"
    }
   },
   "source": [
    "# Danh sách các bộ tiền xử lý\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler, MinMaxScaler, StandardScaler, KernelCenterer\n",
    "\n",
    "scalers = {\n",
    "\t'Normalizer': Normalizer(),\n",
    "\t'MaxAbsScaler': MaxAbsScaler(),\n",
    "\t'MinMaxScaler': MinMaxScaler(),\n",
    "\t'StandardScaler': StandardScaler()\n",
    "}\n",
    "\n",
    "# Từ điển để lưu kết quả\n",
    "results = {}\n",
    "\n",
    "# Lặp qua từng bộ tiền xử lý\n",
    "for name, scaler in scalers.items():\n",
    "\t# Áp dụng bộ tiền xử lý cho tập huấn luyện và tập kiểm tra\n",
    "\tX_train_scaled = scaler.fit_transform(X_train)\n",
    "\tX_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\t# Khởi tạo và huấn luyện mô hình SVM\n",
    "\tmodel = svm.SVC()\n",
    "\tmodel.fit(X_train_scaled, y_train)\n",
    "\n",
    "\t# Dự đoán trên tập kiểm tra\n",
    "\ty_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\t# Tính toán độ chính xác và hệ số F1\n",
    "\taccuracy = accuracy_score(y_test, y_pred)\n",
    "\tf1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "\t# Lưu kết quả\n",
    "\tresults[name] = {\n",
    "\t\t'accuracy': accuracy,\n",
    "\t\t'f1_score': f1\n",
    "\t}\n",
    "\n",
    "# In kết quả\n",
    "for name, metrics in results.items():\n",
    "\tprint(f\"{name}: Accuracy = {metrics['accuracy']:.4f}, F1 Score = {metrics['f1_score']:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer: Accuracy = 0.7966, F1 Score = 0.7064\n",
      "MaxAbsScaler: Accuracy = 0.8814, F1 Score = 0.8610\n",
      "MinMaxScaler: Accuracy = 0.9153, F1 Score = 0.9062\n",
      "StandardScaler: Accuracy = 0.9153, F1 Score = 0.9062\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
